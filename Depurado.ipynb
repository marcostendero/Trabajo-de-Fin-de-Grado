{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25183a5",
   "metadata": {},
   "source": [
    "# Depurado de Datos\n",
    "\n",
    "En esta sección se detalla el proceso de depuración inicial aplicado a los datos de análisis. Se emplea un procedimiento **ETL** (Extract, Transform, Load), lo que implica que se creará una nueva fuente de datos. A partir de los archivos JSON originales, se generará un nuevo conjunto de datos (Data Set) que luego será cargado y procesado en otro programa.\n",
    "\n",
    "Los datos recogidos de forma continua, como la frecuencia cardíaca, la frecuencia respiratoria, el estrés o la batería corporal, pueden presentar valores duplicados en la misma marca temporal o valores faltantes en la serie. El código en esta sección ofrece una solución para abordar estos posibles problemas.\n",
    "\n",
    "Además, ciertos valores pueden resultar poco significativos debido a fallos en los sensores, interfiriendo en la claridad del análisis. Un ejemplo son los valores de frecuencia cardíaca anormalmente altos o bajos y los datos de estrés captados durante el entrenamiento.\n",
    "\n",
    "La depuración abarca el tratamiento de estos problemas mediante cuatro pasos clave:\n",
    "\n",
    "- **Eliminación de datos duplicados:** Se identificarán y eliminarán valores duplicados en una misma marca temporal.\n",
    "\n",
    "- **Relleno de datos faltantes:** Los valores faltantes en la serie temporal se detectarán y rellenarán siguiendo un criterio, usando el valor anterior conocido.\n",
    "\n",
    "- **Descarte de datos anómalos de frecuencia cardíaca:** Los valores de frecuencia cardíaca superiores a 220 bpm o inferiores a 40 bpm (rango estimado para deportistas) se considerarán anómalos y se eliminarán.\n",
    "\n",
    "- **Eliminación de datos de estrés captados durante el entrenamiento:** El periodo de actividad en días de entrenamiento se definirá manualmente, y durante ese tiempo se eliminarán posibles datos de estrés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7525a995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos procesados y guardados en la carpeta de salida.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Carpetas de entrada y salida\n",
    "carpeta_brutos = \"C:/Users/marco/Downloads/datosBrutosTFG/usuario1\"\n",
    "carpeta_procesados = \"C:/Users/marco/Downloads/datosProcesadosTFG/usuario1\"\n",
    "\n",
    "#Diccionario donde se especifican manualmente los entrenamientos para los archivo de estrés\n",
    "entrenamientos = {\n",
    "    \"reloj_36_health_stress_20241007.json\": (\"19:45\", \"01:36\"),  \n",
    "    \"reloj_36_health_stress_20241008.json\": (\"19:03\", \"01:36\"),  \n",
    "    \"reloj_36_health_stress_20241010.json\": (\"19:52\", \"01:28\"),  \n",
    "    \"reloj_36_health_stress_20241011.json\": (\"18:07\", \"01:31\"),  \n",
    "    \"reloj_36_health_stress_20241014.json\": (\"17:37\", \"01:26\"),  \n",
    "    \"reloj_36_health_stress_20241015.json\": (\"17:33\", \"01:15\"),  \n",
    "    \"reloj_36_health_stress_20241017.json\": (\"17:57\", \"01:15\"),  \n",
    "    \"reloj_36_health_stress_20241018.json\": (\"17:35\", \"01:21\"),  \n",
    "}\n",
    "\n",
    "def convertir_a_segundos(hora_str):\n",
    "    #Pasamos el formato de hora:minuto a segundos\n",
    "    horas, minutos = map(int, hora_str.split(\":\"))\n",
    "    return horas * 3600 + minutos * 60\n",
    "\n",
    "def eliminar_duplicados(data):\n",
    "    #Función para eliminar duplicados, dependiendo de si la estructura del JSON es lista o diccionario.\n",
    "    if isinstance(data, list):\n",
    "        resultado = []\n",
    "        tiempos_previos = set()  #Usamos la estructura set para evitar duplicados\n",
    "        for muestra in data:\n",
    "            if muestra[\"startTimeInSeconds\"] not in tiempos_previos:\n",
    "                resultado.append(muestra)\n",
    "                tiempos_previos.add(muestra[\"startTimeInSeconds\"])\n",
    "        return resultado\n",
    "    elif isinstance(data, dict):\n",
    "        resultado = {}\n",
    "        indices_previos = set()\n",
    "        for indice, valor in data.items():\n",
    "            if indice not in indices_previos:\n",
    "                resultado[indice] = valor\n",
    "                indices_previos.add(indice)\n",
    "        return resultado\n",
    "\n",
    "\n",
    "def rellenar_faltantes(data, step=1):\n",
    "    #Función que rellena los valores faltantes con el valor anterior conocido\n",
    "    indices = sorted(map(int, data.keys()))\n",
    "    resultado = {}\n",
    "\n",
    "    for i in range(indices[0], indices[-1] + step, step):\n",
    "        if str(i) in data:\n",
    "            resultado[str(i)] = data[str(i)]\n",
    "        else:\n",
    "            resultado[str(i)] = resultado[str(i - step)]\n",
    "\n",
    "    return resultado\n",
    "\n",
    "\n",
    "def procesar_entrenamiento(data):\n",
    "    #Archivos de entrenamiento. Elimina duplicados y descarta valores FC fuera del rango (40, 220).\n",
    "    for item in data:\n",
    "        if \"samples\" in item:\n",
    "            item[\"samples\"] = eliminar_duplicados(item[\"samples\"])\n",
    "            \n",
    "            item[\"samples\"] = [\n",
    "                muestra for muestra in item[\"samples\"]\n",
    "                if 40 <= muestra.get(\"heartRate\", 0) <= 220 \n",
    "            ]\n",
    "    return data\n",
    "\n",
    "\n",
    "def procesar_resumen_salud(data):\n",
    "    #Archivos de Resumen de Salud. Elimina duplicados y rellena faltantes.\n",
    "    for item in data:\n",
    "        for summary in item.get(\"summaries\", []):\n",
    "            if \"epochSummaries\" in summary:\n",
    "                summary[\"epochSummaries\"] = eliminar_duplicados(summary[\"epochSummaries\"])\n",
    "                summary[\"epochSummaries\"] = rellenar_faltantes(summary[\"epochSummaries\"], step=1)\n",
    "    return data\n",
    "\n",
    "def procesar_estres(data):\n",
    "    #Archivos de Estrés y Body Battery. Elimina duplicados y rellena faltantes.\n",
    "    end_time = start_time + duration\n",
    "\n",
    "    for item in data:\n",
    "        item[\"timeOffsetStressLevelValues\"] = eliminar_duplicados(item[\"timeOffsetStressLevelValues\"])\n",
    "        item[\"timeOffsetStressLevelValues\"] = rellenar_faltantes(item[\"timeOffsetStressLevelValues\"], step=180)\n",
    "\n",
    "        item[\"timeOffsetBodyBatteryValues\"] = eliminar_duplicados(item[\"timeOffsetBodyBatteryValues\"])\n",
    "        item[\"timeOffsetBodyBatteryValues\"] = rellenar_faltantes(item[\"timeOffsetBodyBatteryValues\"], step=180)\n",
    "\n",
    "    return data\n",
    "\n",
    "def procesar_estres_entrenamiento(data, start_time, duration):\n",
    "    #Archivos de Estrés y Body Battery. Elimina duplicados y rellena faltantes.\n",
    "    end_time = start_time + duration\n",
    "\n",
    "    for item in data:\n",
    "        item[\"timeOffsetStressLevelValues\"] = eliminar_duplicados(item[\"timeOffsetStressLevelValues\"])\n",
    "        item[\"timeOffsetStressLevelValues\"] = rellenar_faltantes(item[\"timeOffsetStressLevelValues\"], step=180)\n",
    "\n",
    "        item[\"timeOffsetBodyBatteryValues\"] = eliminar_duplicados(item[\"timeOffsetBodyBatteryValues\"])\n",
    "        item[\"timeOffsetBodyBatteryValues\"] = rellenar_faltantes(item[\"timeOffsetBodyBatteryValues\"], step=180)\n",
    "\n",
    "        #Si hay valores de estrés durante el entrenamiento, los cambiamos por -1\n",
    "        for timestamp, valor in item[\"timeOffsetStressLevelValues\"].items():\n",
    "            timestamp = int(timestamp)\n",
    "            if start_time <= timestamp <= end_time and valor > 0:\n",
    "                item[\"timeOffsetStressLevelValues\"][str(timestamp)] = -1\n",
    "    return data\n",
    "\n",
    "def procesar_estres(data):\n",
    "    #Archivos de Estrés y Body Battery. Elimina duplicados y rellena faltantes.\n",
    "    end_time = start_time + duration\n",
    "\n",
    "    for item in data:\n",
    "        item[\"timeOffsetStressLevelValues\"] = eliminar_duplicados(item[\"timeOffsetStressLevelValues\"])\n",
    "        item[\"timeOffsetStressLevelValues\"] = rellenar_faltantes(item[\"timeOffsetStressLevelValues\"], step=180)\n",
    "\n",
    "        item[\"timeOffsetBodyBatteryValues\"] = eliminar_duplicados(item[\"timeOffsetBodyBatteryValues\"])\n",
    "        item[\"timeOffsetBodyBatteryValues\"] = rellenar_faltantes(item[\"timeOffsetBodyBatteryValues\"], step=180)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "#Bucle principal. Llamada a funciones y gestión de directorios (lectura y guardado)\n",
    "for filename in os.listdir(carpeta_brutos):\n",
    "    #Leemos los datos brutos\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(carpeta_brutos, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        if \"health_stress\" in filename and filename in entrenamientos:\n",
    "            #Convertimos el tiempo de inicio y duración de formato \"HH:MM\" a segundos\n",
    "            start_time_str, duration_str = entrenamientos[filename]\n",
    "            start_time = convertir_a_segundos(start_time_str)\n",
    "            duration = convertir_a_segundos(duration_str)\n",
    "            \n",
    "            data = procesar_estres_entrenamiento(data, start_time, duration)\n",
    "        elif \"health_stress\" in filename and filename not in entrenamientos:\n",
    "            data = procesar_estres(data)\n",
    "        elif \"activity_detail\" in filename:\n",
    "            data = procesar_entrenamiento(data)\n",
    "        elif \"health_snapshot\" in filename:\n",
    "            data = procesar_resumen_salud(data)\n",
    "\n",
    "        #Guardamos los datos ya procesados\n",
    "        procesados = os.path.join(carpeta_procesados, filename)\n",
    "        with open(procesados, \"w\", encoding=\"utf-8\") as outfile:\n",
    "            json.dump(data, outfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Archivos procesados y guardados en la carpeta de salida.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b556c334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
